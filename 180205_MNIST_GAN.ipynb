{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/Data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/Data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST/Data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/Data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./MNIST/Data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 10\n",
    "batch_size  = 100\n",
    "learning_rate = 0.002\n",
    "\n",
    "n_hidden = 256\n",
    "n_input  = 28 * 28\n",
    "n_noise  = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(\n",
    "                    tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(\n",
    "                    tf.matmul(hidden, G_W2) + G_b2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(\n",
    "                    tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(\n",
    "                    tf.matmul(hidden, D_W2) + D_b2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate & Discriminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z)\n",
    "D_gene = discriminator(G)\n",
    "D_real = discriminator(X)\n",
    "\n",
    "loss_D = tf.reduce_mean(tf.log(tf.maximum(D_real, 1e-9)) + tf.log(tf.maximum(1 - D_gene, 1e-9)))\n",
    "loss_G = tf.reduce_mean(tf.log(tf.maximum(D_gene, 1e-9)))\n",
    "\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n",
    "                                                         var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n",
    "                                                         var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: -0.1276 G loss: -6.825\n",
      "Epoch: 0001 D loss: -0.03443 G loss: -6.577\n",
      "Epoch: 0002 D loss: -0.05652 G loss: -6.364\n",
      "Epoch: 0003 D loss: -0.06248 G loss: -5.99\n",
      "Epoch: 0004 D loss: -0.3259 G loss: -4.631\n",
      "Epoch: 0005 D loss: -0.2516 G loss: -6.256\n",
      "Epoch: 0006 D loss: -0.1031 G loss: -6.161\n",
      "Epoch: 0007 D loss: -0.2012 G loss: -4.891\n",
      "Epoch: 0008 D loss: -0.471 G loss: -4.268\n",
      "Epoch: 0009 D loss: -0.3318 G loss: -3.262\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        #plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print('Optimization Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(260.237,9;47.2881x54.36)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "print(ax[3].imshow(np.reshape(samples[3], (28, 28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(samples[3], (28, 28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD1MgZ+7y80LJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2b130898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = np.reshape(samples[3], (28, 28))\n",
    "plt.imshow(im, cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 10\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise, labels):\n",
    "    with tf.variable_scope('generator'):\n",
    "\n",
    "        inputs = tf.concat([noise, labels], 1) ##\n",
    "\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, n_input,\n",
    "                                 activation=tf.nn.sigmoid)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def discriminator(inputs, labels, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, 1,\n",
    "                                 activation=None)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "D_gene = discriminator(G, Y, True)\n",
    "\n",
    "loss_D_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.zeros_like(D_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D = loss_D_real + loss_D_gene\n",
    "loss_G = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                            var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                            var_list=vars_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: 0.007544 G loss: 7.249\n",
      "Epoch: 0001 D loss: 0.006055 G loss: 7.612\n",
      "Epoch: 0002 D loss: 0.01363 G loss: 6.798\n",
      "Epoch: 0003 D loss: 0.03311 G loss: 5.198\n",
      "Epoch: 0004 D loss: 0.03122 G loss: 7.453\n",
      "Epoch: 0005 D loss: 0.05103 G loss: 7.839\n",
      "Epoch: 0006 D loss: 0.06088 G loss: 6.813\n",
      "Epoch: 0007 D loss: 0.06759 G loss: 7.385\n",
      "Epoch: 0008 D loss: 0.02219 G loss: 7.382\n",
      "Epoch: 0009 D loss: 0.05175 G loss: 6.107\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Y: batch_ys, Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G,\n",
    "                           feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                      Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "       # plt.savefig('samples2/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print('Optimization Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncYZ+zTYnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2a4a2cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = np.reshape(samples[6], (28, 28))\n",
    "plt.imshow(im, cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
